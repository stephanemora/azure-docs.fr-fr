- name: Documentation Azure Databricks
  href: index.yml
- name: Vue d’ensemble
  items:
    - name: Présentation d’Azure Databricks
      href: what-is-azure-databricks.md
- name: Démarrages rapides
  expanded: true
  items:
    - name: Créer un espace de travail Databricks - Portail
      href: quickstart-create-databricks-workspace-portal.md
    - name: Créer un espace de travail Databricks - Modèle Resource Manager
      href: quickstart-create-databricks-workspace-resource-manager-template.md
    - name: Créer un espace de travail Databricks - Réseau virtuel
      href: quickstart-create-databricks-workspace-vnet-injection.md
- name: Tutoriels
  items:
    - name: Interroger SQL Server exécuté dans un conteneur Docker
      href: vnet-injection-sql-server.md
    - name: Accéder au stockage à l’aide d’Azure Key Vault
      href: store-secrets-azure-key-vault.md
    - name: Utiliser le point de terminaison de service Cosmos DB
      href: service-endpoint-cosmosdb.md
    - name: Effectuer des opérations ETL
      href: databricks-extract-load-sql-data-warehouse.md
    - name: Diffuser en continu des données à l’aide d’Event Hubs
      href: databricks-stream-from-eventhubs.md
    - name: Analyse des sentiments à l’aide de Cognitive Services
      href: databricks-sentiment-analysis-cognitive-services.md
- name: Concepts
  items:
    - name: Concepts d’Azure Databricks
      href: /azure/databricks/getting-started/concepts
      maintainContext: true
- name: Guides pratiques
  items:
    - name: Guides des langages
      items:
        - name: Python
          href: /azure/databricks/languages/python
          maintainContext: true
        - name: Koalas
          href: /azure/databricks/languages/koalas
          maintainContext: true
        - name: R
          items:
            - name: Guide R
              href: /azure/databricks/spark/latest/sparkr/index
              maintainContext: true
            - name: Vue d’ensemble de SparkR
              href: /azure/databricks/spark/latest/sparkr/overview
              maintainContext: true
            - name: Tutoriels ML SparkR
              items:
                - name: Vue d’ensemble des tutoriels ML SparkR
                  href: /azure/databricks/spark/latest/sparkr/tutorials/index
                  maintainContext: true
                - name: Utiliser glm
                  href: /azure/databricks/spark/latest/sparkr/tutorials/using-glm
                  maintainContext: true
            - name: Informations de référence sur les fonctions SparkR
              href: /azure/databricks/spark/latest/sparkr/sparkr
              maintainContext: true
            - name: "SparkR\_1.6"
              items:
                - name: "Vue d’ensemble de SparkR\_1.6"
                  href: /azure/databricks/spark/1.6/sparkr/overview
                  maintainContext: true
                - name: "Informations de référence sur les fonctions SparkR\_1.6"
                  href: /azure/databricks/spark/1.6/sparkr/functions/index
                  maintainContext: true
            - name: sparklyr
              href: /azure/databricks/spark/latest/sparkr/sparklyr
              maintainContext: true
            - name: RStudio sur Azure Databricks
              href: /azure/databricks/spark/latest/sparkr/rstudio
              maintainContext: true
            - name: Shiny sur Azure Databricks
              href: /azure/databricks/spark/latest/sparkr/shiny
              maintainContext: true
        - name: Scala
          href: /azure/databricks/languages/scala
          maintainContext: true
        - name: SQL
          items:
            - name: Vue d’ensemble de SQL
              href: /azure/databricks/spark/latest/spark-sql/index
              maintainContext: true
            - name: Manuel du langage SQL
              items:
                - name: Modifier la base de données
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/alter-database
                  maintainContext: true
                - name: Modifier la table ou la vue
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/alter-table-or-view
                  maintainContext: true
                - name: Modifier les partitions de la table
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/alter-table-partitions
                  maintainContext: true
                - name: Analyser la table
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/analyze-table
                  maintainContext: true
                - name: Cache
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/cache-dbio
                  maintainContext: true
                - name: Mettre en cache la table
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/cache-table
                  maintainContext: true
                - name: Clear Cache
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/clear-cache
                  maintainContext: true
                - name: Convertir en Delta (Delta Lake sur Azure Databricks)
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/convert-to-delta
                  maintainContext: true
                - name: Créer une base de données
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/create-database
                  maintainContext: true
                - name: Créer une fonction
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/create-function
                  maintainContext: true
                - name: Créer une table
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/create-table
                  maintainContext: true
                - name: Créer une vue
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/create-view
                  maintainContext: true
                - name: Supprimer de (Delta Lake sur Azure Databricks)
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/delete-from
                  maintainContext: true
                - name: Deny
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/deny
                  maintainContext: true
                - name: Décrire la base de données
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/describe-database
                  maintainContext: true
                - name: Décrire la fonction
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/describe-function
                  maintainContext: true
                - name: Décrire l’historique (Delta Lake sur Azure Databricks)
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/describe-history
                  maintainContext: true
                - name: Décrire la table
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/describe-table
                  maintainContext: true
                - name: Supprimer la base de données
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/drop-database
                  maintainContext: true
                - name: Supprimer la fonction
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/drop-function
                  maintainContext: true
                - name: Supprimer la table
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/drop-table
                  maintainContext: true
                - name: Supprimer la vue
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/drop-view
                  maintainContext: true
                - name: Expliquer
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/explain
                  maintainContext: true
                - name: Table de réparation Fsck (Delta Lake sur Azure Databricks)
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/fsck
                  maintainContext: true
                - name: Fonctions
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/functions
                  maintainContext: true
                - name: Accorder
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/grant
                  maintainContext: true
                - name: Generate
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/generate
                  maintainContext: true
                - name: Insérer
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/insert
                  maintainContext: true
                - name: Charger les données
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/load-data
                  maintainContext: true
                - name: Fusionner dans (Delta Lake sur Azure Databricks)
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/merge-into
                  maintainContext: true
                - name: Msck
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/msck
                  maintainContext: true
                - name: Optimiser (Delta Lake sur Azure Databricks)
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/optimize
                  maintainContext: true
                - name: Actualiser la table
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/refresh-table
                  maintainContext: true
                - name: Réinitialiser
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/reset
                  maintainContext: true
                - name: Révoquer
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/revoke
                  maintainContext: true
                - name: Sélectionnez
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/select
                  maintainContext: true
                - name: Définissez
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/set
                  maintainContext: true
                - name: Afficher les colonnes
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/show-columns
                  maintainContext: true
                - name: Afficher Créer la table
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/show-create-table
                  maintainContext: true
                - name: Afficher les bases de données
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/show-databases
                  maintainContext: true
                - name: Afficher les fonctions
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/show-functions
                  maintainContext: true
                - name: Afficher l’octroi
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/show-grant
                  maintainContext: true
                - name: Afficher les partitions
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/show-partitions
                  maintainContext: true
                - name: Afficher les propriétés de la table
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/show-table-properties
                  maintainContext: true
                - name: Afficher les tables
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/show-tables
                  maintainContext: true
                - name: Tronquer la table
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/truncate-table
                  maintainContext: true
                - name: Supprimer la table du cache
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/uncache-table
                  maintainContext: true
                - name: Mettre à jour (Delta Lake sur Azure Databricks)
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/update
                  maintainContext: true
                - name: Utiliser la base de données
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/use-database
                  maintainContext: true
                - name: Nettoyer
                  href: /azure/databricks/spark/latest/spark-sql/language-manual/vacuum
                  maintainContext: true
            - name: Exemples Spark SQL
              items:
                - name: Optimiseur basé sur les coûts
                  href: /azure/databricks/spark/latest/spark-sql/cbo
                  maintainContext: true
                - name: Index utilisé pour ignorer des données
                  href: /azure/databricks/spark/latest/spark-sql/dataskipping-index
                  maintainContext: true
                - name: Écritures transactionnelles dans le stockage cloud avec DBIO
                  href: /azure/databricks/spark/latest/spark-sql/dbio-commit
                  maintainContext: true
                - name: Gérer les enregistrements et les fichiers incorrects
                  href: /azure/databricks/spark/latest/spark-sql/handling-bad-records
                  maintainContext: true
                - name: Préemption des tâches pour une concurrence élevée
                  href: /azure/databricks/spark/latest/spark-sql/preemption
                  maintainContext: true
                - name: Gérer des requêtes longues dans des workflows interactifs
                  href: /azure/databricks/spark/latest/spark-sql/query-watchdog
                  maintainContext: true
                - name: Optimiser la conversion entre DataFrames Spark et Pandas
                  href: /azure/databricks/spark/latest/spark-sql/spark-pandas
                  maintainContext: true
                - name: Fonctions d’agrégation définies par l’utilisateur - Scala
                  href: /azure/databricks/spark/latest/spark-sql/udf-scala
                  maintainContext: true
                - name: Fonctions définies par l’utilisateur - Python
                  href: /azure/databricks/spark/latest/spark-sql/udf-python
                  maintainContext: true
                - name: Fonctions définies par l’utilisateur Pandas
                  href: /azure/databricks/spark/latest/spark-sql/udf-python-pandas
                  maintainContext: true
                - name: Compatibilité avec Apache Hive
                  href: /azure/databricks/spark/latest/spark-sql/compatibility/hive
                  maintainContext: true
    - name: Runtimes Databricks
      items:
        - name: Vue d’ensemble des runtimes
          href: /azure/databricks/runtime/index
          maintainContext: true
        - name: Runtime Databricks
          href: /azure/databricks/runtime/dbr
          maintainContext: true
        - name: Databricks Runtime avec Conda
          href: /azure/databricks/runtime/conda
          maintainContext: true
        - name: Databricks Runtime pour le machine learning
          href: /azure/databricks/runtime/mlruntime
          maintainContext: true
        - name: Databricks Runtime pour Genomics
          href: /azure/databricks/runtime/genomicsruntime
          maintainContext: true
        - name: Databricks Light
          href: /azure/databricks/runtime/light
          maintainContext: true
    - name: Espace de travail
      items:
        - name: Explorer l’espace de travail Databricks
          href: /azure/databricks/workspace/index
          maintainContext: true
        - name: Ressources d’espace de travail
          href: /azure/databricks/workspace/workspace-assets
          maintainContext: true
        - name: Utiliser des objets d’espace de travail
          href: /azure/databricks/workspace/workspace-objects
          maintainContext: true
        - name: 'Obtenir les identificateurs d’espace de travail, de cluster, de notebook et de travail'
          href: /azure/databricks/workspace/workspace-details
          maintainContext: true
    - name: Clusters
      items:
        - name: Vue d’ensemble des clusters
          href: /azure/databricks/clusters/index
          maintainContext: true
        - name: Créer un cluster
          href: /azure/databricks/clusters/create
          maintainContext: true
        - name: Gérer des clusters
          href: /azure/databricks/clusters/clusters-manage
          maintainContext: true
        - name: Configurer des clusters
          href: /azure/databricks/clusters/configure
          maintainContext: true
        - name: Conteneurs personnalisés
          href: /azure/databricks/clusters/custom-containers
          maintainContext: true
        - name: Initialiser des nœuds de cluster
          href: /azure/databricks/clusters/init-scripts
          maintainContext: true
        - name: Clusters compatibles GPU
          href: /azure/databricks/clusters/gpu
          maintainContext: true
        - name: Pools
          items:
            - name: Vue d’ensemble des pools
              href: /azure/databricks/clusters/instance-pools/index
              maintainContext: true
            - name: Afficher les pools
              href: /azure/databricks/clusters/instance-pools/display
              maintainContext: true
            - name: Créer un pool
              href: /azure/databricks/clusters/instance-pools/create
              maintainContext: true
            - name: Configurer un pool
              href: /azure/databricks/clusters/instance-pools/configure
              maintainContext: true
            - name: Modifier un pool
              href: /azure/databricks/clusters/instance-pools/edit
              maintainContext: true
            - name: Supprimer un pool
              href: /azure/databricks/clusters/instance-pools/delete
              maintainContext: true
            - name: Utiliser un pool
              href: /azure/databricks/clusters/instance-pools/cluster-instance-pool
              maintainContext: true
    - name: Notebooks
      items:
        - name: Vue d’ensemble des notebooks
          href: /azure/databricks/notebooks/index
          maintainContext: true
        - name: Gérer des notebooks
          href: /azure/databricks/notebooks/notebooks-manage
          maintainContext: true
        - name: Utiliser des notebooks
          href: /azure/databricks/notebooks/notebooks-use
          maintainContext: true
        - name: Gestion de versions
          items:
            - name: Gestion de versions avec Azure DevOps
              href: /azure/databricks/notebooks/azure-devops-services-version-control
              maintainContext: true
            - name: Gestion de versions avec Bitbucket Cloud
              href: /azure/databricks/notebooks/bitbucket-cloud-version-control
              maintainContext: true
            - name: Gestion de versions avec GitHub
              href: /azure/databricks/notebooks/github-version-control
              maintainContext: true
        - name: Visualisations
          items:
            - name: Visualiser les données
              href: /azure/databricks/notebooks/visualizations/index
              maintainContext: true
            - name: Migrer les graphiques en courbes dépréciés
              href: /azure/databricks/notebooks/visualizations/migrate-charts
              maintainContext: true
            - name: Immersion dans la visualisation dans Python
              href: /azure/databricks/notebooks/visualizations/charts-and-graphs-python
              maintainContext: true
            - name: Immersion dans la visualisation dans Scala
              href: /azure/databricks/notebooks/visualizations/charts-and-graphs-scala
              maintainContext: true
            - name: 'HTML, D3 et SVG dans les notebooks'
              href: /azure/databricks/notebooks/visualizations/html-d3-and-svg
              maintainContext: true
            - name: Bokeh dans les notebooks Python
              href: /azure/databricks/notebooks/visualizations/bokeh
              maintainContext: true
            - name: Matplotlib et ggplot dans les notebooks Python
              href: /azure/databricks/notebooks/visualizations/matplotlib-and-ggplot
              maintainContext: true
            - name: htmlwidgets dans les notebooks R
              href: /azure/databricks/notebooks/visualizations/htmlwidgets
              maintainContext: true
            - name: Plotly dans les notebooks Python et R
              href: /azure/databricks/notebooks/visualizations/plotly
              maintainContext: true
        - name: Tableaux de bord
          href: /azure/databricks/notebooks/dashboards
          maintainContext: true
        - name: Widgets
          href: /azure/databricks/notebooks/widgets
          maintainContext: true
        - name: Workflows des notebooks
          href: /azure/databricks/notebooks/notebook-workflows
          maintainContext: true
        - name: Cellules de package
          href: /azure/databricks/notebooks/package-cells
          maintainContext: true
    - name: travaux
      href: /azure/databricks/jobs
      maintainContext: true
    - name: Bibliothèques
      href: /azure/databricks/libraries
      maintainContext: true
    - name: Données
      items:
        - name: Vue d’ensemble des données
          href: /azure/databricks/getting-started/data
          maintainContext: true
        - name: Bases de données et tables
          href: /azure/databricks/data/tables
          maintainContext: true
        - name: Metastores
          items:
            - name: Metastore Hive externe
              href: /azure/databricks/data/metastores/external-hive-metastore
              maintainContext: true
        - name: Sources de données
          items:
            - name: Bases de données SQL avec JDBC
              href: /azure/databricks/data/data-sources/sql-databases
              maintainContext: true
            - name: Bases de données SQL avec le connecteur Apache Spark
              href: /azure/databricks/data/data-sources/sql-databases-azure
              maintainContext: true
            - name: Stockage Blob Azure
              href: /azure/databricks/data/data-sources/azure/azure-storage
              maintainContext: true
            - name: Azure Data Lake Storage Gen2
              href: /azure/databricks/data/data-sources/azure/azure-datalake-gen2
              maintainContext: true
            - name: Azure Data Lake Storage
              href: /azure/databricks/data/data-sources/azure/azure-datalake
              maintainContext: true
            - name: Passage des informations d’identification Azure Data Lake Storage
              href: /azure/databricks/data/data-sources/azure/adls-passthrough
              maintainContext: true
            - name: Cosmos DB
              href: /azure/databricks/data/data-sources/azure/cosmosdb-connector
              maintainContext: true
            - name: Azure Synapse Analytics
              href: /azure/databricks/data/data-sources/azure/synapse-analytics
              maintainContext: true
            - name: Fichier binaire
              href: /azure/databricks/data/data-sources/binary-file
              maintainContext: true
            - name: Cassandra
              href: /azure/databricks/data/data-sources/cassandra
              maintainContext: true
            - name: Couchbase
              href: /azure/databricks/data/data-sources/couchbase
              maintainContext: true
            - name: ElasticSearch
              href: /azure/databricks/data/data-sources/elasticsearch
              maintainContext: true
            - name: Image
              href: /azure/databricks/data/data-sources/image
              maintainContext: true
            - name: Tables Hive
              href: /azure/databricks/data/data-sources/hive-tables
              maintainContext: true
            - name: Expérience MLflow
              href: /azure/databricks/data/data-sources/mlflow-experiment
              maintainContext: true
            - name: MongoDb
              href: /azure/databricks/data/data-sources/mongodb
              maintainContext: true
            - name: Neo4j
              href: /azure/databricks/data/data-sources/neo4j
              maintainContext: true
            - name: Fichiers Avro
              href: /azure/databricks/data/data-sources/read-avro
              maintainContext: true
            - name: Fichiers CSV
              href: /azure/databricks/data/data-sources/read-csv
              maintainContext: true
            - name: Fichiers JSON
              href: /azure/databricks/data/data-sources/read-json
              maintainContext: true
            - name: Fichiers compressés LZO
              href: /azure/databricks/data/data-sources/read-lzo
              maintainContext: true
            - name: Fichiers Parquet
              href: /azure/databricks/data/data-sources/read-parquet
              maintainContext: true
            - name: Redis
              href: /azure/databricks/data/data-sources/redis
              maintainContext: true
            - name: Série chronologique Riak
              href: /azure/databricks/data/data-sources/riak-ts
              maintainContext: true
            - name: Snowflake
              href: /azure/databricks/data/data-sources/snowflake
              maintainContext: true
            - name: Fichiers ZIP
              href: /azure/databricks/data/data-sources/zip-files
              maintainContext: true
        - name: Système de fichiers Databricks (DBFS)
          href: /azure/databricks/data/databricks-file-system
          maintainContext: true
        - name: Jeux de données Azure Databricks
          href: /azure/databricks/getting-started/databricks-datasets
          maintainContext: true
        - name: FileStore
          href: /azure/databricks/data/filestore
          maintainContext: true
    - name: Intégrations
      items:
        - name: Vue d’ensemble des intégrations
          href: /azure/databricks/integrations/index
          maintainContext: true
        - name: Outils décisionnels
          items:
            - name: Connecter des outils BI
              href: /azure/databricks/bi/jdbc-odbc-bi
              maintainContext: true
            - name: Tableau
              href: /azure/databricks/bi/tableau
              maintainContext: true
            - name: Power BI
              href: /azure/databricks/bi/power-bi
              maintainContext: true
            - name: Alteryx
              href: /azure/databricks/bi/alteryx
              maintainContext: true
            - name: Looker
              href: /azure/databricks/bi/looker
              maintainContext: true
            - name: SQL Workbench/J
              href: /azure/databricks/bi/workbenchj
              maintainContext: true
        - name: Intégrations des données de partenaires
          items:
            - name: Vue d’ensemble des intégrations de partenaires
              href: /azure/databricks/integrations/ingestion/index
            - name: Intégration de Qlik
              href: /azure/databricks/integrations/ingestion/qlik
            - name: Intégration de Fivetran
              href: /azure/databricks/integrations/ingestion/fivetran
            - name: Intégration d’InfoWorks
              href: /azure/databricks/integrations/ingestion/infoworks
            - name: Intégration de StreamSets
              href: /azure/databricks/integrations/ingestion/streamsets
            - name: Intégration de Syncsort
              href: /azure/databricks/integrations/ingestion/syncsort
    - name: Delta Lake
      items:
        - name: Présentation de Delta Lake
          href: /azure/databricks/delta/delta-intro
          maintainContext: true
        - name: Bien démarrer avec Delta Lake
          href: /azure/databricks/delta/quick-start
          maintainContext: true
        - name: Notebooks d’introduction
          href: /azure/databricks/delta/intro-notebooks
          maintainContext: true
        - name: Lectures et écritures par lots sur des tables
          href: /azure/databricks/delta/delta-batch
          maintainContext: true
        - name: Lectures et écritures en streaming sur des tables
          href: /azure/databricks/delta/delta-streaming
          maintainContext: true
        - name: 'Suppression, mise à jour et fusion de tables'
          href: /azure/databricks/delta/delta-update
          maintainContext: true
        - name: Commandes utilitaires sur les tables
          href: /azure/databricks/delta/delta-utility
          maintainContext: true
        - name: Informations de référence sur l’API Delta Lake
          href: /azure/databricks/delta/delta-apidoc
          maintainContext: true
        - name: Contrôle d’accès concurrentiel
          href: /azure/databricks/delta/concurrency-control
          maintainContext: true
        - name: Optimisations
          items:
            - name: Vue d’ensemble des optimisations
              href: /azure/databricks/delta/optimizations/index
              maintainContext: true
            - name: Optimiser les performances avec la gestion des fichiers
              href: /azure/databricks/delta/optimizations/file-mgmt
              maintainContext: true
            - name: Optimisation automatique
              href: /azure/databricks/delta/optimizations/auto-optimize
              maintainContext: true
            - name: Optimiser les performances avec la mise en cache
              href: /azure/databricks/delta/optimizations/delta-cache
              maintainContext: true
            - name: Niveaux d'isolement
              href: /azure/databricks/delta/optimizations/isolation-level
              maintainContext: true
            - name: Répliquer des tables MySQL dans des tables Delta Lake
              href: /azure/databricks/delta/optimizations/mysql-delta
              maintainContext: true
            - name: Optimiser les performances de jointure
              items:
                - name: Vue d’ensemble de l’optimisation des performances de jointure
                  href: /azure/databricks/delta/join-performance/index
                  maintainContext: true
                - name: Optimisation de la jointure de plages
                  href: /azure/databricks/delta/join-performance/range-join
                  maintainContext: true
                - name: Optimisation de la jointure de données asymétriques
                  href: /azure/databricks/delta/join-performance/skew-join
                  maintainContext: true
            - name: Transformation de données optimisée
              items:
                - name: Vue d’ensemble de la transformation de données optimisée
                  href: /azure/databricks/delta/data-transformation/index
                  maintainContext: true
                - name: Fonctions d’ordre supérieur
                  href: /azure/databricks/delta/data-transformation/higher-order-lambda-functions
                  maintainContext: true
                - name: Transformer des types de données complexes
                  href: /azure/databricks/delta/data-transformation/complex-types
                  maintainContext: true
            - name: Meilleures pratiques
              href: /azure/databricks/delta/best-practices
              maintainContext: true
            - name: Gestion des versions des tables
              href: /azure/databricks/delta/optimizations/versioning
              maintainContext: true
            - name: Exemples d’optimisation
              href: /azure/databricks/delta/optimizations/optimization-examples
              maintainContext: true
        - name: Forum aux questions
          href: /azure/databricks/delta/delta-faq
          maintainContext: true
        - name: Autres ressources Delta
          href: /azure/databricks/delta/delta-resources
          maintainContext: true
    - name: DataFrames et jeux de données
      items:
        - name: Vue d’ensemble des DataFrames et des jeux de données
          href: /azure/databricks/spark/latest/dataframes-datasets/index
          maintainContext: true
        - name: Présentation des DataFrames Python
          href: /azure/databricks/spark/latest/dataframes-datasets/introduction-to-dataframes-python
          maintainContext: true
        - name: Présentation des DataFrames Scala
          href: /azure/databricks/spark/latest/dataframes-datasets/introduction-to-dataframes-scala
          maintainContext: true
        - name: Présentation des jeux de données
          href: /azure/databricks/spark/latest/dataframes-datasets/introduction-to-datasets
          maintainContext: true
        - name: Données complexes et imbriquées
          href: /azure/databricks/spark/latest/dataframes-datasets/complex-nested-data
          maintainContext: true
        - name: Agrégateurs
          href: /azure/databricks/spark/latest/dataframes-datasets/aggregators
          maintainContext: true
    - name: Structured Streaming
      items:
        - name: Vue d’ensemble de Structured streaming
          href: /azure/databricks/spark/latest/structured-streaming/index
          maintainContext: true
        - name: Notebooks d’introduction
          href: /azure/databricks/spark/latest/structured-streaming/demo-notebooks
          maintainContext: true
        - name: Sources et récepteurs de données en streaming
          items:
            - name: Vue d’ensemble des sources et des récepteurs
              href: /azure/databricks/spark/latest/structured-streaming/data-sources
              maintainContext: true
            - name: Apache Kafka
              href: /azure/databricks/spark/latest/structured-streaming/kafka
              maintainContext: true
            - name: Hubs d'événements Azure
              href: /azure/databricks/spark/latest/structured-streaming/streaming-event-hubs
              maintainContext: true
            - name: Tables Delta Lake
              href: /azure/databricks/spark/latest/structured-streaming/delta
              maintainContext: true
            - name: Lire et écrire des données Avro en streaming avec des DataFrames
              href: /azure/databricks/spark/latest/structured-streaming/avro-dataframe
              maintainContext: true
            - name: Écrire dans des récepteurs de données arbitraires
              href: /azure/databricks/spark/latest/structured-streaming/foreach
              maintainContext: true
            - name: Stockage Blob Azure optimisé avec Stockage file d’attente Azure
              href: /azure/databricks/spark/latest/structured-streaming/aqs
              maintainContext: true
        - name: Structured Streaming en production
          href: /azure/databricks/spark/latest/structured-streaming/production
          maintainContext: true
        - name: Exemples de streaming
          href: /azure/databricks/spark/latest/structured-streaming/examples
          maintainContext: true
        - name: Spark Streaming (hérité)
          items:
            - name: Vue d’ensemble de Spark Streaming (hérité)
              href: /azure/databricks/spark/latest/rdd-streaming/index
              maintainContext: true
            - name: Déboguer des applications Spark Streaming
              href: /azure/databricks/spark/latest/rdd-streaming/debugging-streaming-applications
              maintainContext: true
            - name: Bonnes pratiques pour le développement d’applications de streaming
              href: /azure/databricks/spark/latest/rdd-streaming/developing-streaming-applications
              maintainContext: true
    - name: Apprentissage automatique
      items:
        - name: Vue d’ensemble du machine learning
          href: /azure/databricks/applications/machine-learning/index
          maintainContext: true
        - name: Apache Spark MLlib
          items:
            - name: Exemple de classification binaire
              href: /azure/databricks/applications/machine-learning/mllib/binary-classification-mllib-pipelines
              maintainContext: true
            - name: Exemple d’arbres de décision
              href: /azure/databricks/applications/machine-learning/mllib/decision-trees
              maintainContext: true
            - name: Structured Streaming et pipelines MLlib
              href: /azure/databricks/applications/machine-learning/mllib/mllib-pipelines-and-stuctured-streaming
              maintainContext: true
            - name: Exemple MLlib avancé
              href: /azure/databricks/applications/machine-learning/mllib/advanced-mllib
              maintainContext: true
        - name: AutoML
          items:
            - name: Vue d’ensemble d’AutoML
              href: /azure/databricks/applications/machine-learning/automl/index
              maintainContext: true
            - name: Hyperopt
              items:
                - name: Vue d’ensemble de Hyperopt
                  href: /azure/databricks/applications/machine-learning/automl/hyperopt/index
                  maintainContext: true
                - name: Hyperopt distribué et suivi MLflow automatisé
                  href: /azure/databricks/applications/machine-learning/automl/hyperopt/hyperopt-spark-mlflow-integration
                  maintainContext: true
                - name: Hyperopt avec HorovodRunner
                  href: /azure/databricks/applications/machine-learning/automl/hyperopt/hyperopt-distributed-ml
                  maintainContext: true
                - name: Bonnes pratiques pour Hyperopt
                  href: /azure/databricks/applications/machine-learning/automl/hyperopt/hyperopt-best-practices
                  maintainContext: true
                - name: Recherche de modèle à l’aide de Hyperopt distribué
                  href: /azure/databricks/applications/machine-learning/automl/hyperopt/hyperopt-model-selection
                  maintainContext: true
            - name: MLlib et suivi MLflow automatisé
              href: /azure/databricks/applications/machine-learning/automl/mllib-mlflow-integration
              maintainContext: true
        - name: Exporter et importer des modèles ML
          items:
            - name: Vue d’ensemble de l’exportation et de l’importation
              href: /azure/databricks/applications/machine-learning/model-export-import/index
              maintainContext: true
            - name: Exportation du modèle ML MLeap
              href: /azure/databricks/applications/machine-learning/model-export-import/mleap-model-export
              maintainContext: true
        - name: Intégration de machine learning tiers
          href: /azure/databricks/applications/machine-learning/third-party/index
          maintainContext: true
    - name: Apprentissage approfondi
      items:
        - name: Vue d’ensemble du deep learning
          href: /azure/databricks/applications/deep-learning/index
          maintainContext: true
        - name: Préparation des données
          items:
            - name: Vue d’ensemble de la préparation des données
              href: /azure/databricks/applications/deep-learning/data-prep/index
              maintainContext: true
            - name: Préparer le stockage pour le chargement de données et le point de contrôle de modèle
              href: /azure/databricks/applications/deep-learning/data-prep/ddl-storage
              maintainContext: true
            - name: Préparer les données pour l’entraînement distribué
              href: /azure/databricks/applications/deep-learning/data-prep/ddl-data
              maintainContext: true
            - name: Charger des données à l’aide de Petastorm
              href: /azure/databricks/applications/deep-learning/data-prep/petastorm
              maintainContext: true
            - name: Enregistrer des DataFrames et des jeux de données dans des fichiers TFRecord
              href: /azure/databricks/applications/deep-learning/data-prep/dataset-to-tfrecords
              maintainContext: true
            - name: Charger des données à partir de fichiers TFRecord avec TensorFlow
              href: /azure/databricks/applications/deep-learning/data-prep/tfrecords-to-tensorflow
              maintainContext: true
            - name: Enregistrer des données dans des fichiers TFRecord avec TensorFlow
              href: /azure/databricks/applications/deep-learning/data-prep/tensorflow-to-tfrecords
              maintainContext: true
            - name: Caractérisation
              items:
                - name: Vue d’ensemble de la caractérisation
                  href: /azure/databricks/applications/deep-learning/featurization/index
                  maintainContext: true
                - name: Transfer learning
                  href: /azure/databricks/applications/deep-learning/featurization/transfer-learning-keras
                  maintainContext: true
        - name: Entraînement d’un seul nœud
          items:
            - name: Vue d’ensemble de l’entraînement d’un seul nœud
              href: /azure/databricks/applications/deep-learning/single-node-training/index
              maintainContext: true
            - name: Pipelines de deep learning
              href: /azure/databricks/applications/deep-learning/single-node-training/deep-learning-pipelines
              maintainContext: true
            - name: TensorFlow
              href: /azure/databricks/applications/deep-learning/single-node-training/tensorflow
              maintainContext: true
            - name: Keras
              href: /azure/databricks/applications/deep-learning/single-node-training/keras
              maintainContext: true
            - name: PyTorch
              href: /azure/databricks/applications/deep-learning/single-node-training/pytorch
              maintainContext: true
            - name: PyTorch à un seul nœud vers DL distribué
              href: /azure/databricks/applications/deep-learning/distributed-training/mnist-pytorch
              maintainContext: true
            - name: Keras à un seul nœud vers DL distribué
              href: /azure/databricks/applications/deep-learning/distributed-training/mnist-tensorflow-keras
              maintainContext: true
            - name: TensorFlow à un seul nœud vers DL distribué
              href: /azure/databricks/applications/deep-learning/distributed-training/mnist-tensorflow
              maintainContext: true
        - name: Entraînement distribué
          items:
            - name: HorovodRunner
              href: /azure/databricks/applications/deep-learning/distributed-training/horovod-runner
              maintainContext: true
            - name: HorovodEstimator
              href: /azure/databricks/applications/deep-learning/distributed-training/horovod-estimator
              maintainContext: true
        - name: Inférence de modèle
          items:
            - name: Vue d’ensemble de l’inférence de modèle
              href: /azure/databricks/applications/deep-learning/inference/index
              maintainContext: true
            - name: Workflow d’inférence de modèle
              href: /azure/databricks/applications/deep-learning/inference/model-inference
              maintainContext: true
            - name: Exemples d’inférence de modèle
              href: /azure/databricks/applications/deep-learning/inference/model-inference-examples
              maintainContext: true
            - name: Inférence de modèle à l’aide de Keras
              href: /azure/databricks/applications/deep-learning/inference/resnet-model-inference-keras
              maintainContext: true
            - name: Inférence de modèle à l’aide de PyTorch
              href: /azure/databricks/applications/deep-learning/inference/resnet-model-inference-pytorch
              maintainContext: true
            - name: Inférence de modèle à l’aide de TensorFlow
              href: /azure/databricks/applications/deep-learning/inference/resnet-model-inference-tensorflow
              maintainContext: true
            - name: Réglage des performances de l’inférence de modèle
              href: /azure/databricks/applications/deep-learning/inference/model-inference-performance
              maintainContext: true
        - name: Solution de référence pour l’inférence de modèle d’image distribuée
          href: /azure/databricks/applications/deep-learning/reference-solutions/images-etl-inference
          maintainContext: true
    - name: MLflow
      items:
        - name: Vue d’ensemble de MLflow
          href: /azure/databricks/applications/mlflow/index
          maintainContext: true
        - name: Prise en main
          items:
            - name: Bien démarrer avec MLflow
              href: /azure/databricks/applications/mlflow/quick-start
              maintainContext: true
            - name: Bien démarrer avec MLflow Java et Scala
              href: /azure/databricks/applications/mlflow/quick-start-java-scala
              maintainContext: true
            - name: Bien démarrer avec MLflow Python
              href: /azure/databricks/applications/mlflow/quick-start-python
              maintainContext: true
            - name: Bien démarrer avec MLflow R
              href: /azure/databricks/applications/mlflow/quick-start-r
              maintainContext: true
        - name: Suivre les exécutions d’entraînement de machine learning
          items:
            - name: Vue d’ensemble du suivi
              href: /azure/databricks/applications/mlflow/tracking
              maintainContext: true
            - name: Entraîner un modèle scikit-learn
              href: /azure/databricks/applications/mlflow/tracking-ex-scikit
              maintainContext: true
            - name: Entraîner un modèle PyTorch
              href: /azure/databricks/applications/mlflow/tracking-ex-pytorch
              maintainContext: true
            - name: Entraîner un modèle PySpark et l’enregistrer aux formats MLeap
              href: /azure/databricks/applications/mlflow/tracking-ex-pyspark
              maintainContext: true
            - name: Suivi des données d’entraînement de modèle ML avec Delta Lake
              href: /azure/databricks/applications/mlflow/tracking-ex-delta
              maintainContext: true
            - name: Accès au suivi en externe
              href: /azure/databricks/applications/mlflow/access-hosted-tracking-server
              maintainContext: true
        - name: Créer des tableaux de bord avec l’API de recherche MLflow
          href: /azure/databricks/applications/mlflow/build-dashboards
          maintainContext: true
        - name: 'Enregistrer, charger et déployer des modèles'
          items:
            - name: 'Vue d’ensemble de l’enregistrement, du chargement et du déploiement'
              href: /azure/databricks/applications/mlflow/models
              maintainContext: true
            - name: Exemple de modèle MLflow
              href: /azure/databricks/applications/mlflow/model-example
              maintainContext: true
            - name: Déploiement de modèle scikit learn sur Azure
              href: /azure/databricks/applications/mlflow/scikit-learn-model-deployment-on-azure-ml
              maintainContext: true
        - name: Reproduire des exécutions avec des projets MLflow
          href: /azure/databricks/applications/mlflow/projects
          maintainContext: true
        - name: Gérer le cycle de vie des modèles MLflow dans le registre de modèle MLflow
          href: /azure/databricks/applications/mlflow/model-registry
          maintainContext: true
        - name: Exemple de registre de modèles MLflow
          href: /azure/databricks/applications/mlflow/model-registry-example
          maintainContext: true
    - name: Analyse des graphes
      items:
        - name: Vue d’ensemble de l’analyse des graphes
          href: /azure/databricks/spark/latest/graph-analysis/index
          maintainContext: true
        - name: GraphFrames
          items:
            - name: Tutoriel sur l’analyse des graphes avec GraphFrames
              href: /azure/databricks/spark/latest/graph-analysis/graphframes/graph-analysis-tutorial
              maintainContext: true
            - name: GraphFrames - Python
              href: /azure/databricks/spark/latest/graph-analysis/graphframes/user-guide-python
              maintainContext: true
            - name: GraphFrames - Scala
              href: /azure/databricks/spark/latest/graph-analysis/graphframes/user-guide-scala
              maintainContext: true
        - name: Analyse des graphes avec GraphX (hérité)
          href: /azure/databricks/spark/latest/graph-analysis/graph-analysis-graphx-tutorial
          maintainContext: true
    - name: Genomics
      items:
        - name: Vue d’ensemble de Genomics
          href: /azure/databricks/applications/genomics/index
          maintainContext: true
        - name: Analyse secondaire
          items:
            - name: Vue d’ensemble de l’analyse secondaire
              href: /azure/databricks/applications/genomics/secondary/index
              maintainContext: true
            - name: Pipeline DNASeq
              href: /azure/databricks/applications/genomics/secondary/dnaseq-pipeline
              maintainContext: true
            - name: Pipeline RNASeq
              href: /azure/databricks/applications/genomics/secondary/rnaseq-pipeline
              maintainContext: true
            - name: Pipeline d’échantillon tumoral/normal
              href: /azure/databricks/applications/genomics/secondary/tumor-normal-pipeline
              maintainContext: true
            - name: Annotation de variantes avec Pipe Transformer
              href: /azure/databricks/applications/genomics/secondary/variant-annotation-pipe
              maintainContext: true
            - name: Méthodes d’annotation de variantes
              href: /azure/databricks/applications/genomics/secondary/annotate-variants
              maintainContext: true
            - name: Pipeline SnpEff
              href: /azure/databricks/applications/genomics/secondary/snpeff-pipeline
              maintainContext: true
            - name: Pipeline Vep
              href: /azure/databricks/applications/genomics/secondary/vep-pipeline
              maintainContext: true
        - name: Analyse tertiaire
          items:
            - name: Vue d’ensemble de l’analyse tertiaire
              href: /azure/databricks/applications/genomics/tertiary/index
              maintainContext: true
            - name: Pipeline de génotypage joint
              href: /azure/databricks/applications/genomics/tertiary/joint-genotyping-pipeline
              maintainContext: true
            - name: SAIGE
              href: /azure/databricks/applications/genomics/tertiary/saige
              maintainContext: true
            - name: "Hail\_0.2"
              href: /azure/databricks/applications/genomics/tertiary/hail
              maintainContext: true
    - name: Migration
      items:
        - name: Migrer des charges de travail de production
          href: /azure/databricks/migration/production
          maintainContext: true
        - name: Migrer un seul nœud
          href: /azure/databricks/migration/single-node
          maintainContext: true
        - name: Migrer des charges de travail vers Delta Lake
          href: /azure/databricks/delta/porting
          maintainContext: true
    - name: Sécurité et confidentialité
      items:
        - name: Présentation de la sécurité
          href: /azure/databricks/security/index
          maintainContext: true
        - name: Base de référence de la sécurité
          href: security-baseline.md
        - name: Contrôle d’accès
          items:
            - name: Présentation du contrôle d’accès
              href: /azure/databricks/security/access-control/index
              maintainContext: true
            - name: Contrôle d’accès aux espaces de travail
              href: /azure/databricks/security/access-control/workspace-acl
              maintainContext: true
            - name: Contrôle d’accès aux clusters
              href: /azure/databricks/security/access-control/cluster-acl
              maintainContext: true
            - name: Contrôle d’accès aux pools
              href: /azure/databricks/security/access-control/pool-acl
              maintainContext: true
            - name: Contrôle d’accès aux travaux
              href: /azure/databricks/security/access-control/job-acl
              maintainContext: true
            - name: Contrôle d’accès aux tables
              items:
                - name: Vue d’ensemble du contrôle d’accès aux tables
                  href: /azure/databricks/security/access-control/table-acls/index
                  maintainContext: true
                - name: Activer le contrôle d’accès aux tables pour un cluster
                  href: /azure/databricks/security/access-control/table-acls/table-acl
                  maintainContext: true
                - name: Privilèges des objets de données
                  href: /azure/databricks/security/access-control/table-acls/object-privileges
                  maintainContext: true
            - name: Contrôle d’accès aux secrets
              href: /azure/databricks/security/access-control/secret-acl
              maintainContext: true
        - name: S’authentifier auprès d’Azure Data Lake Storage avec des informations d’identification Azure Active Directory
          href: /azure/databricks/security/credential-passthrough/adls-passthrough
          maintainContext: true
        - name: Secrets
          items:
            - name: Maintenir les données sécurisées à l’aide de secrets
              href: /azure/databricks/security/secrets/index
              maintainContext: true
            - name: Étendues des secrets
              href: /azure/databricks/security/secrets/secret-scopes
              maintainContext: true
            - name: Secrets
              href: /azure/databricks/security/secrets/secrets
              maintainContext: true
            - name: Rédaction des secrets
              href: /azure/databricks/security/secrets/redaction
              maintainContext: true
            - name: Exemple de workflow de secrets
              href: /azure/databricks/security/secrets/example-secret-workflow
              maintainContext: true
        - name: Bonnes pratiques relatives au RGPD
          href: /azure/databricks/security/privacy/gdpr-delta
        - name: Chiffrer le trafic entre les nœuds worker de cluster
          href: /azure/databricks/security/encryption/encrypt-otw
        - name: Activer des clés gérées par le client pour les notebooks
          href: /azure/databricks/security/keys/customer-managed-key-notebook
        - name: Activer des clés gérées par le client pour DBFS
          href: /azure/databricks/security/keys/customer-managed-keys-dbfs
    - name: Administration
      items:
        - name: Vue d’ensemble de l’administration
          href: /azure/databricks/administration-guide/index
          maintainContext: true
        - name: Console d’administration
          href: /azure/databricks/administration-guide/admin-console
          maintainContext: true
        - name: Gérer votre compte Azure Databricks
          items:
            - name: Vue d’ensemble de la gestion de compte
              href: /azure/databricks/administration-guide/account-settings/index
              maintainContext: true
            - name: Gérer votre abonnement
              href: /azure/databricks/administration-guide/account-settings/account
              maintainContext: true
            - name: Journalisation des diagnostics dans Azure Databricks
              href: /azure/databricks/administration-guide/account-settings/azure-diagnostic-logs
              maintainContext: true
            - name: Superviser l’utilisation en utilisant des étiquettes
              href: /azure/databricks/administration-guide/account-settings/usage-detail-tags-azure
              maintainContext: true
        - name: Gérer les utilisateurs et les groupes
          items:
            - name: Vue d’ensemble des utilisateurs et des groupes
              href: /azure/databricks/administration-guide/users-groups/index
              maintainContext: true
            - name: Gestion des utilisateurs
              href: /azure/databricks/administration-guide/users-groups/users
              maintainContext: true
            - name: Gérer les groupes
              href: /azure/databricks/administration-guide/users-groups/groups
              maintainContext: true
            - name: Configurer l’authentification unique
              href: /azure/databricks/administration-guide/users-groups/single-sign-on/index
              maintainContext: true
            - name: Provisionner des utilisateurs et des groupes avec SCIM
              href: /azure/databricks/administration-guide/users-groups/scim/index
              maintainContext: true
            - name: Configurer le provisionnement SCIM pour AAD
              href: /azure/databricks/administration-guide/users-groups/scim/aad
              maintainContext: true
        - name: Gérer le contrôle d’accès
          items:
            - name: Présentation du contrôle d’accès
              href: /azure/databricks/administration-guide/access-control/index
              maintainContext: true
            - name: Activer le contrôle d’accès aux espaces de travail
              href: /azure/databricks/administration-guide/access-control/workspace-acl
              maintainContext: true
            - name: Activer le contrôle d’accès aux clusters
              href: /azure/databricks/administration-guide/access-control/cluster-acl
              maintainContext: true
            - name: Activer le contrôle d’accès aux pools
              href: /azure/databricks/administration-guide/access-control/pool-acl
              maintainContext: true
            - name: Activer le contrôle d’accès aux travaux
              href: /azure/databricks/administration-guide/access-control/jobs-acl
              maintainContext: true
            - name: Activer le contrôle d’accès aux tables
              href: /azure/databricks/administration-guide/access-control/table-acl
              maintainContext: true
            - name: Activer l’authentification basée sur des jetons
              href: /azure/databricks/administration-guide/access-control/tokens
              maintainContext: true
            - name: Accès conditionnel
              href: /azure/databricks/administration-guide/access-control/conditional-access
              maintainContext: true
            - name: Activer le passage des informations d’identification à Azure Data Lake Storage
              href: /azure/databricks/administration-guide/access-control/credential-passthrough
              maintainContext: true
        - name: Gérer les objets et le comportement des espaces de travail
          items:
            - name: Vue d’ensemble de la gestion des espaces de travail
              href: /azure/databricks/administration-guide/workspace/index
              maintainContext: true
            - name: Gérer le stockage de l’espace de travail
              href: /azure/databricks/administration-guide/workspace/storage
              maintainContext: true
            - name: Gérer les en-têtes de sécurité des espaces de travail
              href: /azure/databricks/administration-guide/workspace/security
              maintainContext: true
            - name: Gérer l’accès aux fonctionnalités de notebook
              href: /azure/databricks/administration-guide/workspace/notebooks
              maintainContext: true
        - name: Activer les configurations de cluster
          items:
            - name: Vue d’ensemble des configurations de cluster
              href: /azure/databricks/administration-guide/clusters/index
              maintainContext: true
            - name: Activer les services de conteneurs
              href: /azure/databricks/administration-guide/clusters/container-services
              maintainContext: true
            - name: Activer Databricks Runtime pour Genomics
              href: /azure/databricks/administration-guide/clusters/genomics-runtime
              maintainContext: true
        - name: Gérer des réseaux virtuels
          items:
            - name: Vue d’ensemble des réseaux virtuels
              href: /azure/databricks/administration-guide/cloud-configurations/azure/index
              maintainContext: true
            - name: Appairer des réseaux virtuels
              href: /azure/databricks/administration-guide/cloud-configurations/azure/vnet-peering
              maintainContext: true
            - name: Passer votre espace de travail de Préversion à Disponibilité générale
              href: /azure/databricks/administration-guide/cloud-configurations/azure/vnet-inject-upgrade
              maintainContext: true
            - name: Déployer Azure Databricks dans votre réseau virtuel
              href: /azure/databricks/administration-guide/cloud-configurations/azure/vnet-inject
              maintainContext: true
            - name: Connecter un espace de travail à un réseau local
              href: /azure/databricks/administration-guide/cloud-configurations/azure/on-prem-network
              maintainContext: true
            - name: Paramètres de routes définies par l’utilisateur
              href: /azure/databricks/administration-guide/cloud-configurations/azure/udr
              maintainContext: true
    - name: Dépannage
      items:
        - name: Questions courantes
          href: /azure/azure-databricks/frequently-asked-questions-databricks
          maintainContext: true
        - name: Administration
          items:
            - name: Qui a supprimé un espace de travail dans Azure
              href: /azure/databricks/kb/administration/who-deleted-workspace
              maintainContext: true
            - name: Qui a supprimé un cluster dans Azure
              href: /azure/databricks/kb/administration/who-deleted-cluster
              maintainContext: true
        - name: Décisionnel
          items:
            - name: Connexions JDBC et ODBC
              href: /azure/databricks/kb/bi/jdbc-odbc-troubleshooting
              maintainContext: true
        - name: Infrastructure Azure
          items:
            - name: Impossible de monter le compte ADLS Gen1
              href: /azure/databricks/kb/cloud/adls-gen1-mount-problem
              maintainContext: true
            - name: ADLException - Erreur d’obtention des informations pour le fichier
              href: /azure/databricks/kb/cloud/azure-vnet-gen1-issue
              maintainContext: true
            - name: Affecter une adresse IP publique unique pour des espaces de travail de réseau virtuel à l’aide du Pare-feu Azure
              href: /azure/databricks/kb/cloud/azure-vnet-single-ip
              maintainContext: true
            - name: Analyser les problèmes de performances de l’interface utilisateur
              href: /azure/databricks/kb/cloud/har-log-analysis
              maintainContext: true
            - name: Les travaux ne progressent pas dans l’espace de travail
              href: /azure/databricks/kb/cloud/azure-vnet-jobs-not-progressing
              maintainContext: true
        - name: Clusters
          items:
            - name: Calculer le nombre de cœurs dans un cluster
              href: /azure/databricks/kb/clusters/calculate-number-of-cores
              maintainContext: true
            - name: Échec de lancement du cluster
              href: /azure/databricks/kb/clusters/cluster-failed-launch
              maintainContext: true
            - name: Limite de demandes d’instances de cœur dans le gestionnaire de cluster
              href: /azure/databricks/kb/clusters/cluster-manager-limit
              maintainContext: true
            - name: L’utilisateur administrateur ne peut pas redémarrer le cluster
              href: /azure/databricks/kb/clusters/cluster-restart-fails-admin-user
              maintainContext: true
            - name: Le paramètre de configuration remplace les paramètres par défaut
              href: /azure/databricks/kb/clusters/conf-overwrites-default-settings
              maintainContext: true
            - name: Remplacer les configurations log4j
              href: /azure/databricks/kb/clusters/overwrite-log4j-logs
              maintainContext: true
            - name: Définir le niveau de journalisation de l’exécuteur
              href: /azure/databricks/kb/clusters/set-executor-log-level
              maintainContext: true
            - name: Arrêt inattendu du cluster
              href: /azure/databricks/kb/clusters/termination-reasons
              maintainContext: true
            - name: L’interface utilisateur Apache Spark affiche moins que la mémoire totale du nœud
              href: /azure/databricks/kb/clusters/spark-shows-less-memory
              maintainContext: true
        - name: Gestion des données
          items:
            - name: Ajouter à un DataFrame
              href: /azure/databricks/kb/data/append-a-row-to-rdd-or-dataframe
              maintainContext: true
            - name: "Cluster Spark\_2.0.0 lent à ajouter des données"
              href: /azure/databricks/kb/data/append-slow-with-spark-2.0.0
              maintainContext: true
            - name: Améliorer les performances avec la mise en compartiments
              href: /azure/databricks/kb/data/bucketing
              maintainContext: true
            - name: Simplifier les transformations chaînées
              href: /azure/databricks/kb/data/chained-transformations
              maintainContext: true
            - name: Vider les tables dans différents formats
              href: /azure/databricks/kb/data/dump-table
              maintainContext: true
            - name: Fonctions UDF Hive
              href: /azure/databricks/kb/data/hive-udf
              maintainContext: true
            - name: Empêcher les colonnes dupliquées sur les jointures DataFrame
              href: /azure/databricks/kb/data/join-two-dataframes-duplicated-columns
              maintainContext: true
            - name: Lister et supprimer des fichiers plus rapidement
              href: /azure/databricks/kb/data/list-delete-files-faster
              maintainContext: true
            - name: Gérer les fichiers Parquet endommagés avec un schéma différent
              href: /azure/databricks/kb/data/match-parquet-schema
              maintainContext: true
            - name: Les valeurs Null et les chaînes vides dans des colonnes partitionnées sont enregistrées comme valeurs Null
              href: /azure/databricks/kb/data/null-empty-strings
              maintainContext: true
            - name: Comportement de la méthode randomSplit
              href: /azure/databricks/kb/data/random-split-behavior
              maintainContext: true
            - name: Générer un schéma à partir d’une classe Case
              href: /azure/databricks/kb/data/schema-from-case-class
              maintainContext: true
            - name: Spécifier des indicateurs d’asymétrie dans les commandes de jointure de jeux de données et de DataFrames
              href: /azure/databricks/kb/data/skew-hints-in-join
              maintainContext: true
            - name: Mettre à jour des colonnes imbriquées
              href: /azure/databricks/kb/data/update-nested-column
              maintainContext: true
            - name: Schéma incompatible dans certains fichiers
              href: /azure/databricks/kb/data/wrong-schema-in-files
              maintainContext: true
        - name: Sources de données
          items:
            - name: Le client ABFS se bloque si l’ID client ou le chemin utilisé est incorrect
              href: /azure/databricks/kb/data-sources/abfs-client-hang
              maintainContext: true
            - name: Erreur de lecture des données d’ADLS Gen1 avec Sparklyr
              href: /azure/databricks/kb/data-sources/access-adls1-from-sparklyr
              maintainContext: true
            - name: Échecs de montage et d’accès au stockage Blob
              href: /azure/databricks/kb/data-sources/access-blob-fails-wasb
              maintainContext: true
            - name: Accès JDBC/ODBC à ADLS Gen2
              href: /azure/databricks/kb/data-sources/access-blobstore-odbc
              maintainContext: true
            - name: Impossible d’accéder à ADLS Gen1 avec un pare-feu
              href: /azure/databricks/kb/data-sources/adls-gen1-firewall-access
              maintainContext: true
            - name: Conflit avec la bibliothèque de connecteurs CosmosDB
              href: /azure/databricks/kb/data-sources/cosmosdb-connector-lib-conf
              maintainContext: true
            - name: Échec de détection de l’encodage dans JSON
              href: /azure/databricks/kb/data-sources/json-unicode
              maintainContext: true
            - name: Impossible de lire les fichiers dans WASB
              href: /azure/databricks/kb/data-sources/wasb-check-blob-types
              maintainContext: true
            - name: Optimiser les performances de lecture des sources de données JDBC
              href: /azure/databricks/kb/data-sources/jdbc-optimize-read
              maintainContext: true
        - name: DBFS
          items:
            - name: Impossible de lire les objets stockés dans une racine DBFS
              href: /azure/databricks/kb/dbfs/dbfs-root-permissions
              maintainContext: true
        - name: Delta Lake
          items:
            - name: Remplir ou mettre à jour des colonnes dans une table Delta Lake
              href: /azure/databricks/kb/delta/backfill-delta-table-cols
              maintainContext: true
            - name: Comportement du cache Delta sur le cluster de mise à l’échelle automatique
              href: /azure/databricks/kb/delta/delta-cache-autoscaling
              maintainContext: true
            - name: Améliorer les performances MERGE INTO avec le nettoyage des partitions
              href: /azure/databricks/kb/delta/delta-merge-into
              maintainContext: true
            - name: Échec des tâches d’écriture
              href: /azure/databricks/kb/delta/delta-write-fails
              maintainContext: true
            - name: Supprimer une table Delta Lake managée
              href: /azure/databricks/kb/delta/drop-delta-table
              maintainContext: true
            - name: La requête UPDATE échoue avec IllegalStateException
              href: /azure/databricks/kb/delta/update-query-fails
              maintainContext: true
        - name: Outils de développeur
          items:
            - name: Erreurs courantes dans Azure Data Factory
              href: /azure/databricks/kb/dev-tools/common-errors-adf
              maintainContext: true
            - name: Jeton d’accès non valide avec Airflow
              href: /azure/databricks/kb/dev-tools/invalid-access-token-airflow
              maintainContext: true
        - name: Exécution des tâches
          items:
            - name: Augmenter le nombre de tâches par étape
              href: /azure/databricks/kb/execution/increase-tasks-per-stage
              maintainContext: true
            - name: Limite de contextes d’exécutions ou de notebooks attachés atteinte
              href: /azure/databricks/kb/execution/maximum-execution-context
              maintainContext: true
            - name: Définir le niveau de journalisation de l’exécuteur
              href: /azure/databricks/kb/execution/set-executor-log-level
              maintainContext: true
            - name: Tâche sérialisée trop grande
              href: /azure/databricks/kb/execution/spark-serialized-task-is-too-large
              maintainContext: true
        - name: travaux
          items:
            - name: Travaux actifs et inactifs
              href: /azure/databricks/kb/jobs/active-vs-dead-jobs
              maintainContext: true
            - name: Limites ADLS CREATE
              href: /azure/databricks/kb/jobs/azure-throttling
              maintainContext: true
            - name: Pilote temporairement indisponible
              href: /azure/databricks/kb/jobs/driver-unavailable
              maintainContext: true
            - name: Supprimer tous les travaux à l’aide de l’API REST
              href: /azure/databricks/kb/jobs/howto-jobsdeleterestapi
              maintainContext: true
            - name: Bibliothèque non installée
              href: /azure/databricks/kb/jobs/job-fails-no-library
              maintainContext: true
            - name: Résoudre les interruptions de travail et collecter les diagnostics
              href: /azure/databricks/kb/jobs/job-hang-resolve-and-collect-diagnostics
              maintainContext: true
            - name: Limite du taux de création de travaux
              href: /azure/databricks/kb/jobs/job-rate-limit
              maintainContext: true
            - name: Échec de création d’une table en mode de remplacement en cas d’interruption
              href: /azure/databricks/kb/jobs/spark-overwrite-cancel
              maintainContext: true
            - name: Blocage d’un travail Spark en raison d’une fonction UDF personnalisée
              href: /azure/databricks/kb/jobs/spark-udf-performance
              maintainContext: true
            - name: Échec du travail avec MaxResultSize
              href: /azure/databricks/kb/jobs/job-fails-maxresultsize-exception
              maintainContext: true
            - name: Échec du travail en raison de l’erreur du package SQLAlchemy
              href: /azure/databricks/kb/jobs/job-fails-sqlalchemy
              maintainContext: true
            - name: Garantir l’idempotence
              href: /azure/databricks/kb/jobs/jobs-idempotency
              maintainContext: true
            - name: Échec des journaux longs avec transfert direct des informations d’identification
              href: /azure/databricks/kb/jobs/azure-long-job-failed-auth
              maintainContext: true
        - name: Bibliothèques
          items:
            - name: Impossible de désinstaller la bibliothèque de l’interface utilisateur
              href: /azure/databricks/kb/libraries/cant-uninstall-libraries
              maintainContext: true
            - name: Erreur d’installation de pyodbc sur un cluster
              href: /azure/databricks/kb/libraries/install-pyodbc-on-cluster
              maintainContext: true
            - name: Indisponibilité d’une bibliothèque provoquant des échecs des travaux
              href: /azure/databricks/kb/libraries/library-install-latency
              maintainContext: true
            - name: Mettre à jour une bibliothèque Maven
              href: /azure/databricks/kb/libraries/maven-library-version-mgmt
              maintainContext: true
        - name: Apprentissage automatique
          items:
            - name: Extraire des informations sur les caractéristiques pour des modèles de pipeline SparkML arborescents
              href: /azure/databricks/kb/machine-learning/extract-feature-info
              maintainContext: true
            - name: Erreur d’ajustement du modèle SparkML
              href: /azure/databricks/kb/machine-learning/fit-spark-model-error
              maintainContext: true
            - name: Validation croisée K-fold de groupe
              href: /azure/databricks/kb/machine-learning/kfold-cross-validation
              maintainContext: true
            - name: Accélérer la validation croisée
              href: /azure/databricks/kb/machine-learning/speed-up-cross-validation
              maintainContext: true
        - name: Metastores
          items:
            - name: Créer des DDL de table à importer dans un metastore externe
              href: /azure/databricks/kb/metastore/create-table-ddl-for-metastore
              maintainContext: true
            - name: Supprimer des tables contenant des métadonnées endommagées
              href: /azure/databricks/kb/metastore/drop-table-corruptedmetadata
              maintainContext: true
            - name: AnalysisException en cas de suppression d’une table d’un metastore Azure
              href: /azure/databricks/kb/metastore/drop-table-exception-azure-metastore
              maintainContext: true
            - name: Problèmes courants liés au metastore Hive
              href: /azure/databricks/kb/metastore/hive-metastore-troubleshooting
              maintainContext: true
            - name: Lister les noms de tables
              href: /azure/databricks/kb/metastore/list-tables
              maintainContext: true
            - name: Configurer un metastore Hive incorporé
              href: /azure/databricks/kb/metastore/set-up-embedded-metastore
              maintainContext: true
            - name: Configurer un metastore Hive sur SQL Server
              href: /azure/databricks/kb/metastore/set-up-sql-backed-hive-metastore
              maintainContext: true
        - name: Mesures
          items:
            - name: Explorer les métriques Spark avec des écouteurs Spark
              href: /azure/databricks/kb/metrics/explore-spark-metrics
              maintainContext: true
            - name: Utiliser des métriques Apache Spark
              href: /azure/databricks/kb/metrics/spark-metrics
              maintainContext: true
        - name: Notebooks
          items:
            - name: Vérifier si une propriété Spark peut être modifiée
              href: /azure/databricks/kb/notebooks/check-spark-property-modifiable
              maintainContext: true
            - name: Erreurs courantes liées aux notebooks
              href: /azure/databricks/kb/notebooks/common-errors-in-notebooks
              maintainContext: true
            - name: Obtenir le chemin complet d’un notebook
              href: /azure/databricks/kb/notebooks/get-notebook-path
              maintainContext: true
            - name: L’enregistrement automatique du notebook échoue en raison des limites de taille de fichiers
              href: /azure/databricks/kb/notebooks/notebook-autosave
              maintainContext: true
            - name: Impossible d’exécuter un notebook après l’annulation de la cellule de streaming
              href: /azure/databricks/kb/notebooks/streaming-notebook-stuck
              maintainContext: true
            - name: Résoudre les problèmes liés à la commande d’annulation
              href: /azure/databricks/kb/notebooks/troubleshoot-cancel-command
              maintainContext: true
        - name: Sécurité et autorisations
          items:
            - name: Échec de la création d’une table avec levée d’une exception de sécurité
              href: /azure/databricks/kb/security/table-create-security-exception
              maintainContext: true
        - name: Python
          items:
            - name: Créer un cluster avec Conda
              href: /azure/databricks/kb/python/anaconda-environment
              maintainContext: true
            - name: Installer et compiler Cython
              href: /azure/databricks/kb/python/cython
              maintainContext: true
            - name: Lire des fichiers volumineux montés sur DBFS
              href: /azure/databricks/kb/python/dbfs-file-size-limit
              maintainContext: true
            - name: Échec de la commande après l’installation de Bokeh
              href: /azure/databricks/kb/python/python-cmd-fails-tornado-version
              maintainContext: true
            - name: Commande annulée en raison d’un conflit de bibliothèque
              href: /azure/databricks/kb/python/python-command-cancelled
              maintainContext: true
            - name: Échec de la commande avec AttributeError
              href: /azure/databricks/kb/python/python-exec-display-cancelled
              maintainContext: true
            - name: Échec du démarrage de Python REPL dans Docker
              href: /azure/databricks/kb/python/python-repl-fails-dcs
              maintainContext: true
            - name: Exécuter du code C++
              href: /azure/databricks/kb/python/running-c-plus-plus-code
              maintainContext: true
            - name: Exécuter des requêtes SQL
              href: /azure/databricks/kb/python/sql-in-python
              maintainContext: true
            - name: Utiliser l’API HDFS pour lire les fichiers dans Python
              href: /azure/databricks/kb/python/hdfs-to-read-files
              maintainContext: true
            - name: "État du sunset de Python\_2"
              href: /azure/databricks/kb/python/python-2-eol
              maintainContext: true
        - name: R avec Spark
          items:
            - name: Changer la version de R
              href: /azure/databricks/kb/r/change-r-version
              maintainContext: true
            - name: Installer des bibliothèques rJava et RJDBC
              href: /azure/databricks/kb/r/install-rjava-rjdbc-libraries
              maintainContext: true
            - name: Résoudre l’erreur de chargement du package ou de l’espace de noms
              href: /azure/databricks/kb/r/namespace-onload
              maintainContext: true
            - name: Conserver et partager du code dans RStudio
              href: /azure/databricks/kb/r/persist-share-code-rstudio
              maintainContext: true
            - name: Corriger la version des packages R
              href: /azure/databricks/kb/r/pin-r-packages
              maintainContext: true
            - name: Échec de rendu d’un fichier Markdown R contenant sparklyr
              href: /azure/databricks/kb/r/rmarkdown-sparklyr-code
              maintainContext: true
            - name: Mettre en parallèle du code R avec gapply
              href: /azure/databricks/kb/r/sparkr-gapply
              maintainContext: true
            - name: Mettre en parallèle du code R avec spark.lapply
              href: /azure/databricks/kb/r/sparkr-lapply
              maintainContext: true
        - name: Spark
          items:
            - name: Exécuter du code C++ dans Scala
              href: /azure/databricks/kb/scala/running-c-plus-plus-code-scala
              maintainContext: true
            - name: Échec des travaux JAR Spark simultanés
              href: /azure/databricks/kb/scala/spark-jar-job-error
              maintainContext: true
        - name: SQL
          items:
            - name: Table ou vue introuvable
              href: /azure/databricks/kb/sql/global-temp-view-not-found
              maintainContext: true
        - name: Diffusion en continu
          items:
            - name: Fichiers de point de contrôle non supprimés quand display() est utilisé
              href: /azure/databricks/kb/streaming/checkpoint-no-cleanup-display
              maintainContext: true
            - name: Fichiers de point de contrôle non supprimés quand foreachBatch() est utilisé
              href: /azure/databricks/kb/streaming/checkpoint-no-cleanup-foreachbatch
              maintainContext: true
            - name: Récupération après changement du répertoire de point de contrôle ou de sortie
              href: /azure/databricks/kb/streaming/file-sink-streaming
              maintainContext: true
            - name: Redémarrer une requête Structured Streaming à partir du dernier décalage écrit
              href: /azure/databricks/kb/streaming/ss-read-from-last-offset
              maintainContext: true
        - name: Visualisations
          items:
            - name: Enregistrer des fichiers Ploty et les afficher à partir de DBFS
              href: /azure/databricks/kb/visualizations/save-plotly-to-dbfs
              maintainContext: true
    - name: Outils de développeur
      items:
        - name: Databricks Connect
          href: /azure/databricks/dev-tools/databricks-connect
          maintainContext: true
        - name: Intégration/déploiement continues
          items:
            - name: CI/CD avec Azure DevOps
              href: /azure/databricks/dev-tools/ci-cd/ci-cd-azure-devops
              maintainContext: true
            - name: CI/CD avec Jenkins
              href: /azure/databricks/dev-tools/ci-cd/ci-cd-jenkins
              maintainContext: true
        - name: Gérer les dépendances dans les pipelines de données
          href: /azure/databricks/dev-tools/data-pipelines
          maintainContext: true
- name: Informations de référence
  items:
    - name: API REST Databricks
      items:
        - name: "API REST\_2.0"
          items:
            - name: Exemples d'API
              href: /azure/databricks/dev-tools/api/latest/examples
              maintainContext: true
            - name: Authentification
              items:
                - name: Jetons d'accès personnels
                  href: /azure/databricks/dev-tools/api/latest/authentication
                  maintainContext: true
                - name: Jetons Azure Active Directory (AAD)
                  items:
                    - name: Vue d’ensemble de l’authentification des jetons AAD
                      href: /azure/databricks/dev-tools/api/latest/aad/index
                      maintainContext: true
                    - name: Obtenir un jeton AAD avec la bibliothèque d’authentification AAD
                      href: /azure/databricks/dev-tools/api/latest/aad/app-aad-token
                      maintainContext: true
                    - name: Obtenir un jeton AAD avec un principal de service
                      href: /azure/databricks/dev-tools/api/latest/aad/service-prin-aad-token
                      maintainContext: true
                    - name: Détecter un problème de jetons d’accès AAD
                      href: /azure/databricks/dev-tools/api/latest/aad/troubleshoot-aad-token
                      maintainContext: true
            - name: Clusters
              href: /azure/databricks/dev-tools/api/latest/clusters
              maintainContext: true
            - name: DBFS
              href: /azure/databricks/dev-tools/api/latest/dbfs
              maintainContext: true
            - name: Groupes
              href: /azure/databricks/dev-tools/api/latest/groups
              maintainContext: true
            - name: API Pools d’instances
              href: /azure/databricks/dev-tools/api/latest/instance-pools
              maintainContext: true
            - name: travaux
              href: /azure/databricks/dev-tools/api/latest/jobs
              maintainContext: true
            - name: Bibliothèques
              href: /azure/databricks/dev-tools/api/latest/libraries
              maintainContext: true
            - name: MLflow
              href: /azure/databricks/dev-tools/api/latest/mlflow
              maintainContext: true
            - name: SCIM
              items:
                - name: Vue d’ensemble de l’API SCIM
                  href: /azure/databricks/dev-tools/api/latest/scim/index
                - name: API SCIM (Me)
                  href: /azure/databricks/dev-tools/api/latest/scim/scim-me
                - name: API SCIM (Users)
                  href: /azure/databricks/dev-tools/api/latest/scim/scim-users
                - name: API SCIM (Groups)
                  href: /azure/databricks/dev-tools/api/latest/scim/scim-group
              maintainContext: true
            - name: Secrets
              href: /azure/databricks/dev-tools/api/latest/secrets
              maintainContext: true
            - name: Jetons
              href: /azure/databricks/dev-tools/api/latest/tokens
              maintainContext: true
            - name: Espace de travail
              href: /azure/databricks/dev-tools/api/latest/workspace
              maintainContext: true
            - name: Chaîne de version du runtime pour les appels d’API REST
              href: /azure/databricks/dev-tools/api/latest/runtime-version-string
              maintainContext: true
        - name: "API REST\_1.2"
          href: /azure/databricks/dev-tools/api/1.2/index
          maintainContext: true
    - name: Databricks Utilities
      href: /azure/databricks/dev-tools/databricks-utils
      maintainContext: true
    - name: Interface CLI Databricks
      items:
        - name: Vue d’ensemble de l’interface CLI Databricks
          href: /azure/databricks/dev-tools/cli/index
          maintainContext: true
        - name: Clusters
          href: /azure/databricks/dev-tools/cli/clusters-cli
          maintainContext: true
        - name: DBFS
          href: /azure/databricks/dev-tools/cli/dbfs-cli
          maintainContext: true
        - name: Groupes
          href: /azure/databricks/dev-tools/cli/groups-cli
          maintainContext: true
        - name: Pools d’instances
          href: /azure/databricks/dev-tools/cli/instance-pools-cli
          maintainContext: true
        - name: travaux
          href: /azure/databricks/dev-tools/cli/jobs-cli
          maintainContext: true
        - name: Bibliothèques
          href: /azure/databricks/dev-tools/cli/libraries-cli
          maintainContext: true
        - name: Secrets
          href: /azure/databricks/dev-tools/cli/secrets-cli
          maintainContext: true
        - name: Pile
          href: /azure/databricks/dev-tools/cli/stack-cli
          maintainContext: true
        - name: Espace de travail
          href: /azure/databricks/dev-tools/cli/workspace-cli
          maintainContext: true
    - name: API REST Azure Databricks
      href: /rest/api/databricks
    - name: Modèle Resource Manager
      href: /azure/templates/microsoft.databricks/workspaces
- name: Ressources
  items:
    - name: Apache Spark
      items:
        - name: Vue d’ensemble d’Apache Spark
          href: /azure/databricks/getting-started/spark/index
          maintainContext: true
        - name: Bien démarrer avec Apache Spark
          href: /azure/databricks/getting-started/spark/quick-start
          maintainContext: true
        - name: DataFrames
          href: /azure/databricks/getting-started/spark/dataframes
          maintainContext: true
        - name: Groupes de données
          href: /azure/databricks/getting-started/spark/datasets
          maintainContext: true
        - name: Apprentissage automatique
          href: /azure/databricks/getting-started/spark/machine-learning
          maintainContext: true
        - name: Structured Streaming
          href: /azure/databricks/getting-started/spark/streaming
          maintainContext: true
        - name: Étapes suivantes
          href: /azure/databricks/getting-started/spark/next
          maintainContext: true
    - name: Formation et FAQ
      href: /azure/databricks/getting-started/training-faq
      maintainContext: true
    - name: Navigateurs pris en charge
      href: /azure/databricks/getting-started/supported-browsers
      maintainContext: true
    - name: Notes de publication
      items:
        - name: Plateforme
          items:
            - name: Notes de publication de la plateforme
              href: /azure/databricks/release-notes/product/index
              maintainContext: true
            - name: Avril 2020
              href: /azure/databricks/release-notes/product/2020/april
              maintainContext: true
            - name: "Mars\_2020"
              href: /azure/databricks/release-notes/product/2020/march
              maintainContext: true
            - name: "Février\_2020"
              href: /azure/databricks/release-notes/product/2020/february
              maintainContext: true
            - name: "Janvier\_2020"
              href: /azure/databricks/release-notes/product/2020/january
              maintainContext: true
            - name: "Décembre\_2019"
              href: /azure/databricks/release-notes/product/2019/december
              maintainContext: true
            - name: "Novembre\_2019"
              href: /azure/databricks/release-notes/product/2019/november
              maintainContext: true
            - name: "2\_octobre\_2019"
              href: /azure/databricks/release-notes/product/2019/october
              maintainContext: true
            - name: "Septembre\_2019"
              href: /azure/databricks/release-notes/product/2019/september
              maintainContext: true
            - name: "Août\_2019"
              href: /azure/databricks/release-notes/product/2019/august
              maintainContext: true
            - name: "Juillet\_2019"
              href: /azure/databricks/release-notes/product/2019/july
              maintainContext: true
            - name: "Juin\_2019"
              href: /azure/databricks/release-notes/product/2019/june
              maintainContext: true
            - name: "Mai\_2019"
              href: /azure/databricks/release-notes/product/2019/may
              maintainContext: true
            - name: Avril 2019
              href: /azure/databricks/release-notes/product/2019/april
              maintainContext: true
            - name: "Mars\_2019"
              href: /azure/databricks/release-notes/product/2019/march
              maintainContext: true
            - name: "Février\_2019"
              href: /azure/databricks/release-notes/product/2019/february
              maintainContext: true
            - name: "Janvier\_2019"
              href: /azure/databricks/release-notes/product/2019/january
              maintainContext: true
            - name: "Décembre\_2018"
              href: /azure/databricks/release-notes/product/2018/december
              maintainContext: true
            - name: Novembre 2018
              href: /azure/databricks/release-notes/product/2018/november
              maintainContext: true
            - name: Octobre 2018
              href: /azure/databricks/release-notes/product/2018/october
              maintainContext: true
            - name: Septembre 2018
              href: /azure/databricks/release-notes/product/2018/september
              maintainContext: true
            - name: "Août\_2018"
              href: /azure/databricks/release-notes/product/2018/august
              maintainContext: true
            - name: Juillet 2018
              href: /azure/databricks/release-notes/product/2018/july
              maintainContext: true
            - name: Juin 2018
              href: /azure/databricks/release-notes/product/2018/june
              maintainContext: true
            - name: "Mai\_2018"
              href: /azure/databricks/release-notes/product/2018/may
              maintainContext: true
            - name: Avril 2018
              href: /azure/databricks/release-notes/product/2018/april
              maintainContext: true
            - name: "Mars\_2018"
              href: /azure/databricks/release-notes/product/2018/march
              maintainContext: true
            - name: "Février\_2018"
              href: /azure/databricks/release-notes/product/2018/february
              maintainContext: true
            - name: Janvier 2018
              href: /azure/databricks/release-notes/product/2018/january
              maintainContext: true
        - name: Runtime Databricks
          items:
            - name: Notes de publication du runtime
              items:
                - name: Versions du runtime
                  href: /azure/databricks/release-notes/runtime/releases
                  maintainContext: true
                - name: "Databricks Runtime\_7.0 ML (bêta)"
                  href: /azure/databricks/release-notes/runtime/7.0ml
                  maintainContext: true
                - name: "Databricks Runtime\_7.0 (bêta)"
                  href: /azure/databricks/release-notes/runtime/7.0
                  maintainContext: true
                - name: "Databricks Runtime\_6.5"
                  href: /azure/databricks/release-notes/runtime/6.5
                  maintainContext: true
                - name: "Databricks Runtime\_6.5 ML"
                  href: /azure/databricks/release-notes/runtime/6.5ml
                  maintainContext: true
                - name: "Databricks Runtime\_6.5 Genomics"
                  href: /azure/databricks/release-notes/runtime/6.5genomics
                  maintainContext: true
                - name: "Databricks Runtime\_6.4"
                  href: /azure/databricks/release-notes/runtime/6.4
                  maintainContext: true
                - name: "Databricks Runtime\_6.4 ML"
                  href: /azure/databricks/release-notes/runtime/6.4ml
                  maintainContext: true
                - name: "Databricks Runtime\_6.4 Genomics"
                  href: /azure/databricks/release-notes/runtime/6.4genomics
                  maintainContext: true
                - name: "Databricks Runtime\_6.3"
                  href: /azure/databricks/release-notes/runtime/6.3
                  maintainContext: true
                - name: "Databricks Runtime\_6.3 ML"
                  href: /azure/databricks/release-notes/runtime/6.3ml
                  maintainContext: true
                - name: "Databricks Runtime\_6.3 Genomics"
                  href: /azure/databricks/release-notes/runtime/6.3genomics
                  maintainContext: true
                - name: "Databricks Runtime\_6.2"
                  href: /azure/databricks/release-notes/runtime/6.2
                  maintainContext: true
                - name: "Databricks Runtime\_6.2 ML"
                  href: /azure/databricks/release-notes/runtime/6.2ml
                  maintainContext: true
                - name: "Databricks Runtime\_6.2 Genomics"
                  href: /azure/databricks/release-notes/runtime/6.2genomics
                  maintainContext: true
                - name: "Databricks Runtime\_6.1"
                  href: /azure/databricks/release-notes/runtime/6.1
                  maintainContext: true
                - name: "Databricks Runtime\_6.1 ML"
                  href: /azure/databricks/release-notes/runtime/6.1ml
                  maintainContext: true
                - name: "Databricks Runtime\_6.0"
                  href: /azure/databricks/release-notes/runtime/6.0
                  maintainContext: true
                - name: "Databricks Runtime\_6.0 avec Conda"
                  href: /azure/databricks/release-notes/runtime/6.0conda
                  maintainContext: true
                - name: "Databricks Runtime\_6.0 ML"
                  href: /azure/databricks/release-notes/runtime/6.0ml
                  maintainContext: true
                - name: "Databricks Runtime\_5.5"
                  href: /azure/databricks/release-notes/runtime/5.5
                  maintainContext: true
                - name: "Databricks Runtime\_5.5 avec Conda"
                  href: /azure/databricks/release-notes/runtime/5.5conda
                  maintainContext: true
                - name: "Databricks Runtime\_5.5 ML"
                  href: /azure/databricks/release-notes/runtime/5.5ml
                  maintainContext: true
                - name: "Databricks Runtime\_5.4"
                  href: /azure/databricks/release-notes/runtime/5.4
                  maintainContext: true
                - name: "Databricks Runtime\_5.4 avec Conda"
                  href: /azure/databricks/release-notes/runtime/5.4conda
                  maintainContext: true
                - name: "Databricks Runtime\_5.4 ML"
                  href: /azure/databricks/release-notes/runtime/5.4ml
                  maintainContext: true
                - name: "Databricks Runtime\_5.3"
                  href: /azure/databricks/release-notes/runtime/5.3
                  maintainContext: true
                - name: "Databricks Runtime\_5.3 ML"
                  href: /azure/databricks/release-notes/runtime/5.3ml
                  maintainContext: true
                - name: "Databricks Light\_2.4"
                  href: /azure/databricks/release-notes/runtime/2.4light
                  maintainContext: true
                - name: "Databricks Runtime\_5.2"
                  href: /azure/databricks/release-notes/runtime/5.2
                  maintainContext: true
                - name: "Databricks Runtime\_5.2 ML"
                  href: /azure/databricks/release-notes/runtime/5.2ml
                  maintainContext: true
                - name: "Databricks Runtime\_5.1"
                  href: /azure/databricks/release-notes/runtime/5.1
                  maintainContext: true
                - name: "Databricks Runtime\_5.1 ML"
                  href: /azure/databricks/release-notes/runtime/5.1ml
                  maintainContext: true
                - name: "Databricks Runtime\_5.0"
                  href: /azure/databricks/release-notes/runtime/5.0
                  maintainContext: true
                - name: "Databricks Runtime\_5.0 ML"
                  href: /azure/databricks/release-notes/runtime/5.0ml
                  maintainContext: true
                - name: "Databricks Runtime\_4.3"
                  href: /azure/databricks/release-notes/runtime/4.3
                  maintainContext: true
                - name: "Databricks Runtime\_4.2"
                  href: /azure/databricks/release-notes/runtime/4.2
                  maintainContext: true
                - name: "Databricks Runtime\_4.1"
                  href: /azure/databricks/release-notes/runtime/4.1
                  maintainContext: true
                - name: "Databricks Runtime\_4.1 ML"
                  href: /azure/databricks/release-notes/runtime/4.1ml
                  maintainContext: true
                - name: "Databricks Runtime\_4.0"
                  href: /azure/databricks/release-notes/runtime/4.0
                  maintainContext: true
                - name: "Databricks Runtime\_3.5 LTS"
                  href: /azure/databricks/release-notes/runtime/3.5
                  maintainContext: true
                - name: "Databricks Runtime\_3.4"
                  href: /azure/databricks/release-notes/runtime/3.4
                  maintainContext: true
            - name: Mises à jour de maintenance
              href: /azure/databricks/release-notes/runtime/maintenance-updates
              maintainContext: true
            - name: Cycle de vie de la prise en charge du runtime
              href: /azure/databricks/release-notes/runtime/databricks-runtime-ver
              maintainContext: true
        - name: Types de versions
          href: /azure/databricks/release-notes/release-types
          maintainContext: true
    - name: Page d’état Azure Databricks
      href: /azure/databricks/status
      maintainContext: true
    - name: Guide du développeur R
      href: /azure/machine-learning/r-developers-guide
    - name: Feuille de route Azure
      href: 'https://azure.microsoft.com/roadmap/?category=analytics'
    - name: Tarifs
      href: 'https://azure.microsoft.com/pricing/details/databricks/'
    - name: Poser une question - Forum MSDN
      href: 'https://social.msdn.microsoft.com/Forums/en-US/home?forum=AzureDatabricks'
    - name: Poser une question - Stack Overflow
      href: 'https://stackoverflow.com/questions/tagged/azure-databricks'
    - name: Disponibilité des régions
      href: 'https://azure.microsoft.com/regions/services/'
    - name: Options de support
      href: 'https://azure.microsoft.com/support/options/'