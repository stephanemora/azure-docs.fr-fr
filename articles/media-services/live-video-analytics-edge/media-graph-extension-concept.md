---
title: Présentation de l’extension de graphe multimédia – Azure
description: Live Video Analytics sur IoT Edge vous permet d’étendre les fonctionnalités de traitement de graphe multimédia via un nœud d’extension de graphe.
ms.topic: overview
ms.date: 09/14/2020
ms.openlocfilehash: 2e1ca730a6736776425cd70b323147b58e8eacbf
ms.sourcegitcommit: 6fc156ceedd0fbbb2eec1e9f5e3c6d0915f65b8e
ms.translationtype: HT
ms.contentlocale: fr-FR
ms.lasthandoff: 08/21/2020
ms.locfileid: "88716076"
---
# <a name="media-graph-extension"></a>Extension de graphe multimédia

Live Video Analytics sur IoT Edge vous permet d’étendre les fonctionnalités de traitement de graphe multimédia via un nœud d’extension de graphe. Votre plug-in d’extension Analytics peut utiliser des techniques de traitement d’image traditionnelles ou des modèles d’IA de vision par ordinateur. Les extensions de graphe sont activées en incluant un nœud de processeur d’extension dans un graphe multimédia. Le nœud de processeur d’extension relaie les images vidéo vers le point de terminaison configuré et agit en tant qu’interface de votre extension. La connexion peut être établie à un point de terminaison local ou distant. Elle peut être sécurisée par une authentification et un chiffrement TLS, si nécessaire. En outre, le nœud de processeur d’extension de graphe permet la mise à l’échelle et l’encodage facultatifs des images vidéo avant leur envoi à votre extension personnalisée.

Live Video Analytics prend en charge deux types de processeurs d’extension de graphe multimédia :

* [Processeur d’extension HTTP](media-graph-concept.md#http-extension-processor)
* [Processeur d’extension gRPC](media-graph-concept.md#grpc-extension-processor)

## <a name="http-extension-processor"></a>Processeur d’extension HTTP

Le processeur d’extension HTTP permet des scénarios d’extensibilité à l’aide du protocole HTTP, où les performances et/ou l’utilisation optimale des ressources ne constituent pas la préoccupation principale. Vous pouvez exposer votre propre IA à un graphe multimédia via un point de terminaison REST HTTP. 

Utilisez le nœud de processeur d’extension HTTP lorsque :

* Vous souhaitez une meilleure interopérabilité avec les systèmes d’inférence HTTP existants.
* Un transfert de données à faibles performances est acceptable.
* Vous voulez utiliser une interface de requête-réponse simple avec Live Video Analytics.

## <a name="grpc-extension-processor"></a>Processeur d’extension gRPC

Le processeur d’extension gRPC permet des scénarios d’extensibilité à l’aide d’un protocole structuré hautement performant, basé sur gRPC. Il est idéal pour les scénarios où les performances et/ou l’utilisation optimale des ressources sont une priorité. Le processeur d’extension gRPC permet de tirer pleinement parti des définitions de données structurées. gRPC offre de hautes performances de transfert de contenu avec :

* la [mémoire partagée intégrée](https://en.wikipedia.org/wiki/Shared_memory) ou 
* l’incorporation directe du contenu dans le corps des messages gRPC. 

Le processeur d’extension gRPC peut être utilisé pour envoyer les propriétés multimédias tout en échangeant les messages d’inférence.
Par conséquent, utilisez un nœud de processeur d’extension gRPC lorsque :

* Vous voulez utiliser un contrat structuré (par exemple, des messages structurés pour les requêtes et les réponses)
* Vous voulez utiliser des mémoires tampons de protocole ([protobuf](https://developers.google.com/protocol-buffers)) comme format d’échange de messages sous-jacent pour la communication.
* Vous voulez communiquer avec un serveur gRPC dans une session de flux unique à la place du modèle de requête-réponse traditionnel nécessitant un gestionnaire de demandes personnalisé pour analyser les requêtes entrantes et appeler les fonctions d’implémentation appropriées. 
* Vous voulez une faible latence et une communication à haut débit entre Live Video Analytics et votre module.

## <a name="use-your-inferencing-model-with-live-video-analytics"></a>Utiliser votre modèle d’inférence avec Live Video Analytics

Les extensions de graphe multimédia vous permettent d’exécuter les modèles d’inférence de votre choix sur un runtime d’inférence disponible quelconque, comme ONNX, TensorFlow, PyTorch ou autres, dans votre propre conteneur Docker. L’extension personnalisée d’inférence doit être déployée en même temps que le module Live Video Analytics de périphérie pour optimiser les performances. Elle est alors appelée via le processeur d’extension HTTP ou le processeur d’extension gRPC inclus dans votre topologie de graphe. De plus, la fréquence des appels dans votre extension personnalisée peut être limitée par l’ajout facultatif d’un [processeur de détection de mouvement](media-graph-concept.md#motion-detection-processor) et d’un [processeur de filtre de fréquence d’images ](media-graph-concept.md#frame-rate-filter-processor) en amont du processeur d’extension multimédia.

Le diagramme ci-dessous illustre le flux de données général :
 
![Flux de données](./media/media-graph-extension/data-flow.png)

## <a name="samples"></a>Exemples

Passez en revue quelques-uns de nos exemples de [notebook Jupyter](https://github.com/Azure/live-video-analytics/blob/master/utilities/video-analysis/notebooks/readme.md) pour Live Video Analytics. Ces notebooks fournissent des instructions pas à pas sur :

* La création d’une image conteneur Docker d’un service d’extension
* Le déploiement du service d’extension en tant que conteneur avec le conteneur Live Video Analytics
* L’utilisation d’un graphe multimédia Live Video Analytics avec un client d’extension et son pointage vers le point de terminaison gRPC de l’extension
